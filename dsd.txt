# Function to migrate table data to S3
def migrate_table_data_to_s3(table_name):
    try:
        conn = connect_redshift()
        cursor = conn.cursor()

        # Get the columns ordered correctly
        cursor.execute(f"SELECT column_name FROM information_schema.columns WHERE table_name = '{table_name}' ORDER BY ordinal_position")
        columns = [row[0] for row in cursor.fetchall()]

        # Query the table data
        cursor.execute(f"SELECT * FROM orbit_64407564mmy3009.{table_name};")
        rows = cursor.fetchall()
        
        # Convert data to CSV format in memory
        csv_buffer = io.StringIO()
        csv_writer = csv.writer(csv_buffer)

        # Write the header
        csv_writer.writerow(columns)
        
        # Write the rows (ensure they align with the columns)
        csv_writer.writerows(rows)
        
        # Upload CSV data to S3
        s3_key = f"snowflake_poc/{table_name}.csv"
        s3_client.put_object(Bucket=AWS_BUCKET_NAME, Key=s3_key, Body=csv_buffer.getvalue())
        logging.info(f"Uploaded data for table {table_name} to S3.")
        
        cursor.close()
        conn.close()
    except Exception as e:
        logging.error(f"Error migrating data for table {table_name}: {e}")
        raise
