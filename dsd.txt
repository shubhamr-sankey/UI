import psycopg2
import snowflake.connector
import logging
import re
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import serialization

# -------------------------------------------
# Redshift connection configuration
# -------------------------------------------
REDSHIFT_HOST = 'medai-orbit.cqibeghf1hd5.us-east-1.redshift.amazonaws.com'
REDSHIFT_PORT = '5439'
REDSHIFT_USER = 'orbit_sa_read_only'
REDSHIFT_PASSWORD = '419iKpjj-zPX'
REDSHIFT_DB = 'orbit'

# -------------------------------------------
# Snowflake connection configuration
# -------------------------------------------
sf_user = 'SA-JRDUS-ORBIT-ENG-D'
sf_account = 'jrd-bt-useast.privatelink'
sf_warehouse = 'WH_ORBIT_DEV_ETL'
sf_database = 'ORBIT_DEV'
sf_schema = 'CERBA'
sf_role = 'ITS_APP_DEV_RDDW_ORBIT_DEVELOPERS'

# Path to your private key (.p8 or .pem)
PRIVATE_KEY_PATH = 'sa-jrdus-orbit-eng-d_rsa_key.p8'
PRIVATE_KEY_PASSPHRASE = b'0rB1THkjSu9'

# -------------------------------------------
# Set up logging
# -------------------------------------------
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    filename='view_migration.log',
    filemode='w'
)

# -------------------------------------------
# Load private key for Snowflake
# -------------------------------------------
def get_private_key():
    try:
        with open(PRIVATE_KEY_PATH, "rb") as key_file:
            private_key = serialization.load_pem_private_key(
                key_file.read(),
                password=PRIVATE_KEY_PASSPHRASE,
                backend=default_backend()
            )
        return private_key.private_bytes(
            encoding=serialization.Encoding.DER,
            format=serialization.PrivateFormat.PKCS8,
            encryption_algorithm=serialization.NoEncryption()
        )
    except Exception as e:
        logging.error(f"Error loading private key: {e}")
        raise

# -------------------------------------------
# Function to connect to Redshift
# -------------------------------------------
def connect_to_redshift():
    try:
        connection = psycopg2.connect(
            dbname=REDSHIFT_DB,
            user=REDSHIFT_USER,
            password=REDSHIFT_PASSWORD,
            host=REDSHIFT_HOST,
            port=REDSHIFT_PORT
        )
        logging.info("Connected to Redshift successfully.")
        return connection
    except Exception as e:
        logging.error(f"Error connecting to Redshift: {e}")
        raise

# -------------------------------------------
# Function to connect to Snowflake
# -------------------------------------------
def connect_to_snowflake():
    try:
        private_key = get_private_key()
        connection = snowflake.connector.connect(
            user=sf_user,
            account=sf_account,
            private_key=private_key,
            warehouse=sf_warehouse,
            database=sf_database,
            schema=sf_schema,
            role=sf_role
        )
        logging.info("Connected to Snowflake successfully.")
        return connection
    except Exception as e:
        logging.error(f"Error connecting to Snowflake: {e}")
        raise

# -------------------------------------------
# Function to fetch Snowflake tables and views
# -------------------------------------------
def fetch_snowflake_objects():
    connection = connect_to_snowflake()
    cursor = connection.cursor()
    try:
        # Fetch tables
        cursor.execute(f"SHOW TABLES IN SCHEMA {sf_database}.{sf_schema}")
        tables = {row[1].lower(): row[1] for row in cursor.fetchall()}

        # Fetch views
        cursor.execute(f"SHOW VIEWS IN SCHEMA {sf_database}.{sf_schema}")
        views = {row[1].lower(): row[1] for row in cursor.fetchall()}

        # Combine tables and views
        object_mapping = {**tables, **views}
        logging.info(f"Fetched {len(object_mapping)} objects (tables and views) from Snowflake.")
        return object_mapping
    finally:
        connection.close()

# -------------------------------------------
# Function to verify table and column existence in Snowflake
# -------------------------------------------
def verify_table_columns(tables):
    conn = connect_to_snowflake()
    cursor = conn.cursor()
    try:
        for table in tables:
            cursor.execute(f"SELECT * FROM {sf_schema}.{table} LIMIT 1")
            columns = [desc[0] for desc in cursor.description]
            logging.info(f"Columns in {table}: {columns}")
    except Exception as e:
        logging.error(f"Error verifying table {table}: {e}")
        raise
    finally:
        conn.close()

# -------------------------------------------
# Function to fetch Redshift view definitions
# -------------------------------------------
def fetch_redshift_views(view_name=None):
    connection = connect_to_redshift()
    cursor = connection.cursor()
    try:
        if view_name:
            cursor.execute(f"""
                SELECT 
                    v.table_name,
                    pg_get_viewdef(quote_ident(v.table_schema) || '.' || quote_ident(v.table_name), true) AS view_definition
                FROM information_schema.views v
                WHERE v.table_schema = 'orbit_64407564mmy3009' AND v.table_name = '{view_name}'
            """)
        else:
            cursor.execute("""
                SELECT 
                    v.table_name,
                    pg_get_viewdef(quote_ident(v.table_schema) || '.' || quote_ident(v.table_name), true) AS view_definition
                FROM information_schema.views v
                WHERE v.table_schema = 'orbit_64407564mmy3009'
            """)
        views = cursor.fetchall()
        logging.info(f"Fetched {len(views)} views from Redshift.")
        return views
    finally:
        connection.close()

# -------------------------------------------
# Function to map Redshift table/column names to Snowflake
# -------------------------------------------
def map_table_names_in_view(view_definition, object_mapping):
    if view_definition is None:
        logging.warning("View definition is None, cannot map table names.")
        return None

    # Step 1: Replace table/view names
    for redshift_name, snowflake_name in object_mapping.items():
        quoted_redshift_name = f'"{redshift_name}"'
        quoted_snowflake_name = f'"{snowflake_name}"'
        view_definition = view_definition.replace(redshift_name, quoted_snowflake_name)
        view_definition = view_definition.replace(quoted_redshift_name, quoted_snowflake_name)

    # Step 2: Fix column names with underscores
    view_definition = view_definition.replace('"SPECIMEN"_type', '"SPECIMEN_type"')
    view_definition = view_definition.replace('vendor_"SPECIMEN"_type', 'vendor_"SPECIMEN_type"')
    view_definition = view_definition.replace('"SPECIMEN"_class', '"SPECIMEN_class"')
    view_definition = view_definition.replace('"STUDY"_id', '"STUDY_id"')

    # General fix for any remaining incorrectly quoted identifiers
    view_definition = re.sub(r'"\w+"_\w+', lambda m: f'"{m.group(0).replace("_", "")}"', view_definition)

    # Step 3: Replace Redshift-specific syntax
    view_definition = view_definition.replace('~~', 'LIKE')  # Pattern matching
    view_definition = view_definition.replace('substring(', 'SUBSTRING(')  # Function casing
    view_definition = view_definition.replace('initcap(', 'INITCAP(')  # Function casing
    view_definition = view_definition.replace(
        "(('now'::text)::date - ('1 year'::interval * (\"SECOND\".age)::double precision))",
        "DATEADD(YEAR, - \"SECOND\".age, CURRENT_DATE)"
    )

    return view_definition

# -------------------------------------------
# Function to create views in Snowflake
# -------------------------------------------
def create_view_in_snowflake(view_name, view_definition):
    if view_definition is None:
        logging.error(f"Cannot create view {view_name}: view definition is None.")
        return

    connection = connect_to_snowflake()
    cursor = connection.cursor()
    try:
        quoted_view_name = f'"{sf_schema}"."{view_name}"'
        create_view_query = f'CREATE OR REPLACE VIEW {quoted_view_name} AS {view_definition}'
        logging.info(f"Executing query:\n{create_view_query}")
        cursor.execute(create_view_query)
        connection.commit()
        logging.info(f"Created view {view_name} in Snowflake.")
    except Exception as e:
        logging.error(f"Error creating view {view_name} in Snowflake: {e}")
        connection.rollback()
    finally:
        connection.close()

# -------------------------------------------
# Function to migrate views from Redshift to Snowflake
# -------------------------------------------
def migrate_views_to_snowflake(view_name=None):
    try:
        # Fetch views from Redshift
        views = fetch_redshift_views(view_name)
        if not views:
            logging.warning(f"No views found for {view_name or 'all views'}.")
            return

        # Fetch Snowflake objects
        object_mapping = fetch_snowflake_objects()

        # Verify table existence
        required_tables = ['sid', 'v', 'sp', 'c']  # Replace with actual table names
        verify_table_columns(required_tables)

        # Migrate each view
        for view in views:
            view_name, view_definition = view
            logging.info(f"Migrating view {view_name}...")

            # Map Redshift names to Snowflake
            snowflake_view_definition = map_table_names_in_view(view_definition, object_mapping)
            if snowflake_view_definition is None:
                logging.warning(f"Skipping view {view_name} due to missing definition.")
                continue

            # Create the view in Snowflake
            create_view_in_snowflake(view_name, snowflake_view_definition)

        logging.info("View migration completed successfully.")
    except Exception as e:
        logging.error(f"Error during view migration: {e}")
        raise

# -------------------------------------------
# Main execution
# -------------------------------------------
if __name__ == "__main__":
    try:
        migrate_views_to_snowflake(view_name="code_validation_vw")
    except Exception as e:
        logging.critical(f"Critical error during view migration: {e}")
